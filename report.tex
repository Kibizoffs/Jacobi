\documentclass[a4paper, fleqn]{report}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}

\usepackage{amsmath}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{tocbibind}

\geometry{top=2cm, bottom=2cm, left=2.5cm, right=2.5cm}

\title{
\textbf{Московский Государственный Университет имени М.В.\ Ломоносова}\\
\textbf{Факультет вычислительной математики и кибернетики}\\
\textbf{Введение в численные методы}\\
Отчёт по практическому заданию
}

\author{
Студент Кибизов Кирилл, группа 207
}
\date{\number\year}

\begin{document}

\maketitle

\tableofcontents

\chapter*{Постановка задачи}

\section*{Дано:}
\begin{enumerate}[label=\arabic*.]
\item Уравнение в частных производных с граничными условиями:
\[
\begin{cases}
k_x \frac{\partial^2 u}{\partial x^2} + k_y \frac{\partial^2 u}{\partial y^2} = 0, \quad (x, y) \in [0, 1] \times [0, 1], \\
u(x, 0) = 0, \quad x \in [0, 1] \\
u(0, y) = 0, \quad y \in [0, 1] \\
u(x, 1) = \sin(\pi x), \quad x \in [0, 1] \\
u(1, y) = 0, \quad y \in [0, 1] \\
\end{cases}
\]
\item Разностная схема:
\[
\begin{cases}
k_x \dfrac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + k_y \dfrac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} = 0, \quad i = \overline{1,N-1},\ j = \overline{1,N-1}, \\
u_{i,0} = 0, \quad i = \overline{0,N}, \\
u_{0,j} = 0, \quad j = \overline{0,N}, \\
u_{i,N} = 0, \quad i = \overline{0,N}, \\
u_{N,j} = 0, \quad j = \overline{0,N}.
\end{cases}
\]
где
\[
u_{i,j} \approx u(x_i, y_j), \quad x_i = \dfrac{i}{N}, \quad y_j = \dfrac{j}{N}, \quad h = \dfrac{1}{N}.
\]
\item Аналитическое решение данной задачи:
\[
u(x, y) = \dfrac{\sinh(\pi y)}{\sinh(\pi)} \sin(\pi x)
\]
\end{enumerate}

\section*{Задача:}
\textbf{Требуется решить данную СЛАУ с помощью итерационного метода Якоби (где он применим)} для $N = 100$, рассматривая следующие случаи:
\begin{enumerate}
    \item $k_x = k_y = 1$,
    \item $k_x = 1$, $k_y = 10^6$.
\end{enumerate}
\textbf{В случае неприменимости итерационного метода якоби предложить рабочий альтернативный метод.}


\chapter*{Описание используемых числовых методов}
Процедура решения СЛАУ Ax=f с плохо обусловленной матрицей А посредством прямых методов может приводить к существенным округлениям. Этого недостатка лишены итерационные методы. Однако итерационные методы могут быит использованы для решения СЛАУ только при условии его сходимости. Для исследования сходимости введём две характеристики:

\section*{Формирование матрицы}

\subsection*{Выбор внутренних узлов}
Мы рассматриваем только внутренние точки сетки, так как на граничных точках значения функции уже известны из граничных условий. Таким образом, неизвестными остаются только значения $u_{i,j}$ в узлах, которые расположены внутри области (не на границе). Эти неизвестные образуют вектор $u$.

\subsection*{Строки и столбцы матрицы $A$}
Каждая строка матрицы $A$ соответствует уравнению, полученному для одного внутреннего узла $(i,j)$.  
Каждый столбец матрицы $A$ соответствует неизвестной величине $u_{m,n}$ в некотором другом внутреннем узле $(m,n)$.  
Таким образом, размерность матрицы $A$ равна количеству внутренних узлов.

\subsection*{Связь между узлами и уравнениями}
Для каждого внутреннего узла мы записываем уравнение, которое связывает значение $u_{i,j}$ со значениями в соседних узлах:
\begin{itemize}
    \item слева $(i-1,j)$,
    \item справа $(i+1,j)$,
    \item сверху $(i,j+1)$,
    \item снизу $(i,j-1)$.
\end{itemize}
Это уравнение получается из аппроксимации вторых производных по $x$ и $y$ с помощью конечных разностей.

\chapter*{Анализ применимости используемых числовых методов}

Перед тем как применять итерационные методы для решения системы линейных алгебраических уравнений (СЛАУ), необходимо убедиться, что они сходятся в рассматриваемом случае. Это включает в себя проверку структуры и свойств матрицы системы, а также оценку выполнения достаточных условий сходимости итерационных методов.

\section*{Достаточные условия сходимости итерационного процесса}

\textbf{Теорема Самарского.} \\
Пусть $A$ — самосопряжённая положительно определённая матрица:  
$A = A^T, \quad A > 0,$  
и $B = A - \frac{\tau}{2} A$ — положительно определённая матрица, $\tau$ — положительное число:  
$B = A - \frac{\tau}{2} A > 0.$

\subsection*{Самосопряжённость матрицы}
В одномерном случае в направлении $x$ вторая производная $\frac{\partial^2 u}{\partial x^2}$ аппроксимируется по формуле:
\[
\frac{\partial^2 u}{\partial x^2} \approx \frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h_x^2}.
\]
Важно, что коэффициенты при $u_{i+1,j}$ и $u_{i-1,j}$ одинаковы (оба равны $\frac{1}{h_x^2}$).  
Аналогично производится аппроксимация второй производной по оси $y$.
Благодаря симметрии разностной схемы все связи между узлами в матрице $A$ получаются парными и зеркальными. Если уравнение для узла $(i,j)$ ссылается на узел $(i+1,j)$ с некоторым коэффициентом, то и уравнение для узла $(i+1,j)$ будет иметь аналогичный коэффициент при $u_{i,j}$. Это обеспечивает симметричность матрицы. Известные значения на границах области не делают матрицу несимметричной, так как они просто выносятся в вектор правой части $f$. Таким образом, можно сделать вывод, что матрица $A$ — самосопряжённая. В случае вещественной матрицы (все элементы матрицы $A$ — вещественные) понятия самосопряжённости и симметричности совпадают.

\subsection*{Положительно определённая матрица}
Чтобы доказать, что матрица $A$ положительно определённая, нужно показать, что для любого ненулевого вектора $v$ выполняется неравенство: $v^T A v > 0$.
Рассмотрим выражение $v^T A v$. Это скаляр, который можно записать как:
\[
v^T A v = \sum_{i,j} v_{i,j} (Av)_{i,j}.
\]
Для матрицы $A$, полученной из разностной аппроксимации второго порядка, можно записать, что $A$ действует на вектор $v$ следующим образом:
\[
(Av)_{i,j} = \frac{k_x}{h^2}(v_{i+1,j} - 2v_{i,j} + v_{i-1,j}) + \frac{k_y}{h^2}(v_{i,j+1} - 2v_{i,j} + v_{i,j-1}).
\]
Подставим это в $v^T A v$ и раскроем сумму:
\[
v^T A v = \sum_{i,j} v_{i,j} \left( \frac{k_x}{h^2}(v_{i+1,j} - 2v_{i,j} + v_{i-1,j}) + \frac{k_y}{h^2}(v_{i,j+1} - 2v_{i,j} + v_{i,j-1}) \right).
\]
При раскрытии суммы оказывается, что многие члены взаимно сокращаются. Итоговый результат можно выразить через квадраты разностей значений $v$ в соседних узлах. После упрощений получим:
\[
v^T A v = \sum_{i,j} \frac{k_x}{h^2} (v_{i+1,j} - v_{i,j})^2 + \frac{k_y}{h^2} (v_{i,j+1} - v_{i,j})^2.
\]
В выражении $v^T A v$ остались только суммы квадратов разностей значений $v$ в соседних узлах. Так как $k_x > 0$, $k_y > 0$ и $h > 0$, каждый член суммы неотрицателен. Более того, если вектор $v$ ненулевой, то хотя бы одно из слагаемых будет строго больше нуля.
Поскольку $v^T A v$ является суммой строго неотрицательных слагаемых, и каждое из них положительно, если $v \neq 0$, то $v^T A v > 0$. Это доказывает, что матрица $A$ положительно определённая.


На основе доказательства положительной определённости матрицы $A$, можно утверждать, что для матрицы $A$, которая:
\begin{itemize}
    \item симметрична ($A^T = A$),
    \item положительно определённая ($v^T A v > 0$ для любого $v \neq 0$),
\end{itemize}
выполняются достаточные условия сходимости итерационных методов, таких как метод Якоби, метод Зейделя и метод релаксации (SOR). 

\subsection*{Сходимость методов}
В итоге методы Якоби, Зейделя, верхней релаксации (SOR) применимы, к данной задаче, однако важно также учитывать:
\begin{itemize}
    \item \textbf{Точность решения:} Точность определяется выбранным критерием остановки (например, достижением малого значения невязки или изменения решения между итерациями).
    \item \textbf{Быстрота сходимости:} Для улучшения быстроты сходимости можно:
    \begin{itemize}
        \item уменьшить шаг $h$,
        \item использовать "ускоряющие" параметры, такие как $\omega$ в методе верхней релаксации,
    \end{itemize}
\end{itemize}

\chapter*{Реализация используемых числовых методов}


\chapter*{Заключение}


\begin{thebibliography}{2}
\renewcommand{\bibname}{Литература}
\bibitem{kostomarov}
Костомаров Д.\,П., Фаворский А.\,П. \textit{Вводные лекции по численным методам}. — М.: Логос, 2004. — 184 с.
\bibitem{samar}
Самарский А.\,А. \textit{Введение в численные методы}. — М.: Наука, 1989. — 416 с.
\end{thebibliography}

\end{document}
